{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import torchvision.transforms.functional\n",
    "# import torchvision.transforms.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Planet : Amazon space -- Full model running for multilabel classification\n",
    "\n",
    "!! This is supposed to become the main jupyternotebook to run the multilabel classification and testing !!\n",
    "\n",
    "Usefull links:\n",
    "<https://learnopencv.com/multi-label-image-classification-with-pytorch-image-tagging/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0) Initialization\n",
    "### 0.1) Getting Module and Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from Multilabel_Amazon_Engine import checking_folder, train, show_4_image_in_batch, batch_prediction\n",
    "from Multilabel_Amazon_Module import AmazonSpaces, MultiLayerCNN, AdjustSaturation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_folder = '../IPEO_Planet_project'\n",
    "if not os.path.exists(data_folder):\n",
    "    data_folder = input(\"Enter the data folder path: \")\n",
    "    assert os.path.exists(data_folder), \"I did not find the folder at, \"+str(data_folder)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1) Putting the model on the gpu"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "model = MultiLayerCNN().to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### + Load previously trained model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "if device==\"cpu\":\n",
    "    model.load_state_dict(torch.load('model_multilabel_classification.pth', map_location=torch.device('cpu')))\n",
    "else:\n",
    "    model.load_state_dict(torch.load('model_multilabel_classification.pth'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "MultiLayerCNN(\n  (conv1): Conv2d(3, 10, kernel_size=(5, 5), stride=(1, 1))\n  (pool_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n  (pool_avg): AvgPool2d(kernel_size=4, stride=4, padding=0)\n  (fc): Linear(in_features=14580, out_features=17, bias=True)\n  (batchNorm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (loss): BCELoss()\n  (sig): Sigmoid()\n)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2) Getting the different datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_csv = 'training.csv'\n",
    "validation_csv = 'validation.csv'\n",
    "test_csv = 'test.csv'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "Transform_choice = transforms.Compose([transforms.ToTensor(), transforms.CenterCrop(256),transforms.RandomAutocontrast(p=1), AdjustSaturation(1.2)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_dataset = AmazonSpaces(csv_file=train_csv,\n",
    "                                    root_dir=f'{data_folder}/train-jpg', transform=Transform_choice)\n",
    "validation_dataset = AmazonSpaces(csv_file=validation_csv,\n",
    "                                    root_dir=f'{data_folder}/train-jpg', transform=Transform_choice)\n",
    "test_dataset = AmazonSpaces(csv_file=test_csv,\n",
    "                                    root_dir=f'{data_folder}/train-jpg', transform=Transform_choice)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3) Wrapping into the different dataloaders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size,drop_last = True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size,drop_last = True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, drop_last=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4) Choice of Criterion and Opitimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.01)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5) TRAINING"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\gezas\\anaconda3\\envs\\IPEO\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "1it [00:02,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 256, 256])\n",
      "(64, 17) (64, 17)\n",
      "Predicted : [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], calculated accuracy score: 0.8823529411764706, prediction score : 0.0, recall score: 0.0\n",
      "Loss : 0.6821922768509426, calculated accuracy score: 0.8823529411764706, prediction score : 0.0, recall score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gezas\\anaconda3\\envs\\IPEO\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "21it [00:48,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.3403016141122093, calculated accuracy score: 0.963235294117647, prediction score : 0.9047619047619048, recall score: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [01:36,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.18709528775072215, calculated accuracy score: 0.9811692969870877, prediction score : 0.9512195121951219, recall score: 0.8399390243902439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [02:22,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.12878648125081993, calculated accuracy score: 0.9873432979749278, prediction score : 0.9672131147540983, recall score: 0.8924180327868853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [03:17,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.09817952418933926, calculated accuracy score: 0.9904684095860565, prediction score : 0.9753086419753086, recall score: 0.9189814814814815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [04:04,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.07938281896504885, calculated accuracy score: 0.992355853232382, prediction score : 0.9801980198019802, recall score: 0.9350247524752475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121it [04:52,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.06666431397998877, calculated accuracy score: 0.9936193485658725, prediction score : 0.9834710743801653, recall score: 0.9457644628099173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "141it [05:37,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.07016021638035225, calculated accuracy score: 0.9910956403838131, prediction score : 0.9731493794326241, recall score: 0.9364472517730497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "161it [06:22,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.06336046336086727, calculated accuracy score: 0.992201772013153, prediction score : 0.9764848602484473, recall score: 0.94434200310559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "165it [06:31,  2.29s/it]C:\\Users\\gezas\\anaconda3\\envs\\IPEO\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "181it [07:06,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.07004929588303449, calculated accuracy score: 0.9899760318492038, prediction score : 0.9561205110497238, recall score: 0.9277517499297687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [07:52,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.08432088011853288, calculated accuracy score: 0.9847591088674275, prediction score : 0.9439287935323384, recall score: 0.9075004034362605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "221it [08:37,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.08362749424485469, calculated accuracy score: 0.9837428466861858, prediction score : 0.9462388291855203, recall score: 0.9084300897768703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "241it [09:24,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.08641881937903967, calculated accuracy score: 0.9825405784720527, prediction score : 0.9424171704589257, recall score: 0.9058424857461672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "261it [10:10,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.09688383688777569, calculated accuracy score: 0.9771417906242956, prediction score : 0.9399688183970613, recall score: 0.8906201694890712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "281it [11:01,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.10680522124770558, calculated accuracy score: 0.9722171341846346, prediction score : 0.9305625502454018, recall score: 0.8779969118084952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [11:53,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.11596659156763779, calculated accuracy score: 0.9656323285128005, prediction score : 0.923618482523295, recall score: 0.8598188354022839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "321it [12:52,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.1295800072416978, calculated accuracy score: 0.9573369067253068, prediction score : 0.9136126978192897, recall score: 0.8377684772101841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "341it [13:50,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.143776915293081, calculated accuracy score: 0.9494808737277902, prediction score : 0.9053887743761334, recall score: 0.8127353185927209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "361it [14:49,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.15724939516497835, calculated accuracy score: 0.9420446675900277, prediction score : 0.8993668240359258, recall score: 0.7856652689778004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "375it [15:30,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_14828\\1205884589.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mThe_results\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_dataloader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_dataloader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m=\u001B[0m \u001B[0moptim\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0.01\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss_fn\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcriterion\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\MA1\\IPEO\\ipeo-amazon\\Multilabel_Amazon_Engine.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(model, train_loader, validation_dataloader, device, optimizer, lr, epochs, loss_fn)\u001B[0m\n\u001B[0;32m    145\u001B[0m         tl, ta, a_s, p_s, r_s, h_l = train_epoch(model, train_loader, optimizer=optimizer, lr=lr, loss_fn=loss_fn,\n\u001B[0;32m    146\u001B[0m                                                  device=device)\n\u001B[1;32m--> 147\u001B[1;33m         \u001B[0mvl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mva\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mva_s\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvp_s\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvr_s\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvh_l\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalidate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_dataloader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss_fn\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mloss_fn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    148\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"Epoch {ep:2}, Train acc={ta:.3f}, Val acc={va:.3f}, Train loss={tl:.3f}, Val loss={vl:.3f}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\MA1\\IPEO\\ipeo-amazon\\Multilabel_Amazon_Engine.py\u001B[0m in \u001B[0;36mvalidate\u001B[1;34m(model, dataloader, device, loss_fn)\u001B[0m\n\u001B[0;32m     39\u001B[0m     \u001B[0maccs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0macc_scores\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprec_scores\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrec_scores\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtot_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mham_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     40\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Validating'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 41\u001B[1;33m     \u001B[1;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     42\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mi_batch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_batch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataloader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m             \u001B[0mimage_batch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msample_batch\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'image'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "The_results = train(model, train_dataloader, validation_dataloader, device=device, optimizer= optim, lr = 0.01, epochs=1, loss_fn=criterion)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'The_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_14828\\2577344491.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m# create json object from dictionary\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mjs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mjson\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdumps\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mThe_results\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;31m# open file for writing, \"w\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'The_results' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# create json object from dictionary\n",
    "js = json.dumps(The_results)\n",
    "\n",
    "# open file for writing, \"w\"\n",
    "f = open(\"training_results.json\",\"a\")\n",
    "\n",
    "# write json object to file\n",
    "f.write(js)\n",
    "\n",
    "# close file\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6) TESTING"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:03<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valloss 0.69, val accuracy 82.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# store stats\n",
    "losses, accuracies = [], []\n",
    "all_pred = []\n",
    "for batch in tqdm(test_dataloader):\n",
    "    # TODO run prediction_step\n",
    "    loss, accuracy, predictions = batch_prediction(batch, model, device = 'cuda')\n",
    "\n",
    "    # append to stats\n",
    "    losses.append(loss)\n",
    "    accuracies.append(accuracy)\n",
    "    all_pred.append(predictions)\n",
    "# average val losses and accuracies over batches\n",
    "losses, accuracies = np.stack(losses).mean(), np.stack(accuracies).mean()\n",
    "print(f\"valloss {losses:.2f}, val accuracy {accuracies*100:.2f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.30012019, 0.07512019, 0.81850962, 0.94975962, 0.81165865,\n       0.69002404, 0.79471154, 0.93173077, 0.88257212, 0.90216346,\n       0.99026442, 0.97319712, 0.9890625 , 0.98942308, 0.99639423,\n       0.99254808, 0.99507212])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pred = np.stack(all_pred, axis = 0).mean(axis=0)\n",
    "mean_pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Saving Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model_multilabel_classification.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model_multilabel_classification.pth\")\n",
    "print(\"Saved PyTorch Model State to model_multilabel_classification.pth\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
