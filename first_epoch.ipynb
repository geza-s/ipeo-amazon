{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d33fd99-e3dc-408a-aea1-08646313c1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in /Users/annahalloy/opt/anaconda3/envs/IPEO/lib/python3.7/site-packages (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8bd6eb3-fa9b-4c56-8710-c114fc9322f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import torchvision.transforms.functional\n",
    "# import torchvision.transforms.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29e8ff-28d7-4ad5-8901-dcfda5ae7cda",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924870f0-56f4-49e5-994d-17cd41e3fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/annahalloy/Documents/EPFL/MA1/IPEO/dataset_amazon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14b59bbe-2268-4360-8354-41ecd546fbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the data folder path:  /Users/annahalloy/Documents/EPFL/MA1/IPEO/dataset_amazon\n"
     ]
    }
   ],
   "source": [
    "from Multilabel_Amazon_Engine import checking_folder, train, show_4_image_in_batch, batch_prediction\n",
    "from Multilabel_Amazon_Module import AmazonSpaces, MultiLayerCNN, AdjustSaturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49eff55f-0f9a-4038-a715-4efa679ebdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the data folder path:  /Users/annahalloy/Documents/EPFL/MA1/IPEO/dataset_amazon\n"
     ]
    }
   ],
   "source": [
    "data_folder = '../IPEO_Planet_project'\n",
    "if not os.path.exists(data_folder):\n",
    "    data_folder = input(\"Enter the data folder path: \")\n",
    "    assert os.path.exists(data_folder), \"I did not find the folder at, \"+str(data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5b6195-a19f-4427-a722-a736ab3d0d9f",
   "metadata": {},
   "source": [
    "### model on gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4ee8e41-f698-4941-984f-2f8a8f61c9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "342902e1-43fb-4912-a4d5-8c8b330af132",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiLayerCNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c2315a-7a16-43c3-83a4-63a3b8153de3",
   "metadata": {},
   "source": [
    "### Load different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b0a1f5c-0597-43ef-b121-1ab183cc0f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = 'training.csv'\n",
    "validation_csv = 'validation.csv'\n",
    "test_csv = 'test.csv'\n",
    "\n",
    "Transform_choice = transforms.Compose([transforms.ToTensor(), transforms.CenterCrop(256),transforms.RandomAutocontrast(p=1), AdjustSaturation(1.2)])\n",
    "\n",
    "train_dataset = AmazonSpaces(csv_file=train_csv,\n",
    "                                    root_dir=f'{data_folder}/train-jpg', transform=Transform_choice)\n",
    "validation_dataset = AmazonSpaces(csv_file=validation_csv,\n",
    "                                    root_dir=f'{data_folder}/train-jpg', transform=Transform_choice)\n",
    "test_dataset = AmazonSpaces(csv_file=test_csv,\n",
    "                                    root_dir=f'{data_folder}/train-jpg', transform=Transform_choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ffb65-ca72-4895-ab13-808ee1adfe60",
   "metadata": {},
   "source": [
    "### Dataloader, criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "351b90ea-7438-46f1-9f82-de15f31258db",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size,drop_last = True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size,drop_last = True)\n",
    "### ON TOUCHE PAS CA\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30811f21-2ccc-41ca-b4a7-b22110dde8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd92739-54a2-413e-bb3a-dcaee5f95714",
   "metadata": {},
   "source": [
    "### Define a single training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27c3e598-6aed-443b-b4a9-79eb1ea19ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.006136296316981316\n"
     ]
    }
   ],
   "source": [
    "weight_value_before = float(model.fc.weight[0,0])\n",
    "print(weight_value_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00a77302-f58e-4c59-a8de-7960522c6d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take a single batch manually (next(enumerate(iterator)) just takes one element at a time)\n",
    "idx, batch = next(enumerate(train_dataloader))\n",
    "\n",
    "model.train() # set model to training mode\n",
    "optim.zero_grad() # make sure gradients are all zeroed\n",
    "\n",
    "# retrieve image and label from the batch\n",
    "x, y = batch['image'], batch['labels']\n",
    "\n",
    "device = \"cpu\" # specify to run this operation on GPU (otherwise write \"cpu\")\n",
    "\n",
    "# move model and data to device\n",
    "model = model.to(device)\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "# TODO: make forward pass (i.e., prediction) of x with the model\n",
    "y_prediction = model(x)\n",
    "\n",
    "# TODO: calculate the loss\n",
    "loss = criterion(y_prediction, y)\n",
    "\n",
    "# backpropoagation of gradients\n",
    "loss.backward() \n",
    "\n",
    "# update model parameters\n",
    "optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d14996d-4cbc-42c6-89c3-1e25312e8a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6772, dtype=torch.float64,\n",
       "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aca8a3d5-5ea2-4339-9d84-8823987bbfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.006079344544559717\n",
      "-0.0056951590813696384\n"
     ]
    }
   ],
   "source": [
    "# let's print the value of a single weight after the training step\n",
    "weight_value_after = float(model.fc.weight[0,0])\n",
    "print(weight_value_after)\n",
    "\n",
    "# we can also print the gradient of this weight\n",
    "weight_gradient = float(model.fc.weight.grad[0,0])\n",
    "print(weight_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21f0decd-f632-4b7c-b92b-88549c3e6705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.006079 == -0.006079 ?\n"
     ]
    }
   ],
   "source": [
    "# TODO: manual SGD\n",
    "lr = 0.01\n",
    "manually_updated_weight = weight_value_before - lr * weight_gradient\n",
    "\n",
    "print(f\"{weight_value_after:.6f} == {manually_updated_weight:.6f} ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a78168-d5e6-4816-a455-b6aaf1b17cba",
   "metadata": {},
   "source": [
    "### two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22741cfb-7f15-41ec-9679-97fc3914e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiLayerCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10,\n",
    "                               kernel_size=5)  # Input is a 3 plane 256x256 tensor (RBB) -> output 10 planes of 254x254\n",
    "        self.pool_max = nn.MaxPool2d(2, 2)  # output of dim-2 x dim-2\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)  # input 10 planes 127x127, output 20 planes of 125x125\n",
    "        self.pool_avg = nn.AvgPool2d(4, 4)\n",
    "        self.fc = nn.Linear(20 * 27 * 27, 17)  # single dense layer for the network\n",
    "        self.batchNorm = nn.BatchNorm2d(3)\n",
    "        self.loss = nn.BCELoss()\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batchNorm(x)\n",
    "        print(f\"step 1 : {x.shape}\")\n",
    "        x = self.pool_max(nn.functional.relu(self.conv1(x)))\n",
    "        print(f\"step 2 : {x.shape}\")\n",
    "        x = self.pool_avg(x)\n",
    "        print(f\"step 3 : {x.shape}\")\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        print(f\"step 4 : {x.shape}\")\n",
    "        x = x.view(-1, 20 * 27 * 27)\n",
    "        print(f\"step 5 : {x.shape}\")\n",
    "        x = self.fc(x)\n",
    "        print(f\"step 6 : {x.shape}\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd129b41-1a9e-4449-a3b6-1c3cea57d535",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLOUD_MultiLayerCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CLOUD_MultiLayerCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10,\n",
    "                               kernel_size=10)  # Input is a 3 plane 256x256 tensor (RBB) -> \n",
    "                                                # output 10 planes of 218x218\n",
    "        self.pool_max = nn.MaxPool2d(4, 4)  # output of dim-2 x dim-2\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)  # input 10 planes 127x127, output 20 planes of 125x125\n",
    "        self.pool_avg = nn.AvgPool2d(2, 2)\n",
    "        self.fc = nn.Linear(13520, 3)  # single dense layer for the network\n",
    "        self.batchNorm = nn.BatchNorm2d(3)\n",
    "        self.loss = nn.BCELoss()\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.dropped = nn.Dropout(p=0.1, inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.conv1(x)\n",
    "        # print(f\"step 0 : {x.shape}\")\n",
    "        x = self.batchNorm(x)\n",
    "        print(f\"step 1 : {x.shape}\")\n",
    "        x = self.dropped(self.pool_max(nn.functional.relu(self.conv1(x))))\n",
    "        print(f\"step 2 : {x.shape}\")\n",
    "        x = self.pool_avg(x)\n",
    "        print(f\"step 3 : {x.shape}\")\n",
    "        x = self.dropped(nn.functional.relu(self.conv2(x)))\n",
    "        print(f\"step 4 : {x.shape}\")\n",
    "        x = x.view(-1, 20 *26*26)\n",
    "        print(f\"step 5 : {x.shape}\")\n",
    "        x = self.fc(x)\n",
    "        print(f\"step 6 : {x.shape}\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46bfa56e-f5f0-4c1b-9d54-034b3e5fa454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLOUD_MultiLayerCNN(\n",
       "  (conv1): Conv2d(3, 10, kernel_size=(10, 10), stride=(1, 1))\n",
       "  (pool_max): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool_avg): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (fc): Linear(in_features=13520, out_features=3, bias=True)\n",
       "  (batchNorm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (loss): BCELoss()\n",
       "  (sig): Sigmoid()\n",
       "  (dropped): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = CLOUD_MultiLayerCNN()\n",
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11b49ed9-2762-42b9-89d3-6f046879df80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1 : torch.Size([16, 3, 256, 256])\n",
      "step 2 : torch.Size([16, 10, 61, 61])\n",
      "step 3 : torch.Size([16, 10, 30, 30])\n",
      "step 4 : torch.Size([16, 20, 26, 26])\n",
      "step 5 : torch.Size([16, 13520])\n",
      "step 6 : torch.Size([16, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1976, -0.0446, -0.1900],\n",
       "        [-0.1295, -0.0140, -0.1165],\n",
       "        [-0.0932,  0.0017, -0.0851],\n",
       "        [-0.1577,  0.1086, -0.0597],\n",
       "        [ 0.0053,  0.0592, -0.1413],\n",
       "        [-0.0675,  0.0342, -0.0844],\n",
       "        [-0.1595,  0.0109, -0.2051],\n",
       "        [-0.2241,  0.0099, -0.1764],\n",
       "        [-0.1321,  0.0368, -0.1782],\n",
       "        [-0.0803, -0.0909, -0.1248],\n",
       "        [-0.2188, -0.0160, -0.2475],\n",
       "        [-0.1684,  0.0463, -0.1923],\n",
       "        [-0.2458, -0.0603, -0.1407],\n",
       "        [-0.2321, -0.0163, -0.0838],\n",
       "        [-0.1525, -0.0224, -0.0815],\n",
       "        [-0.1524, -0.0223, -0.1155]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c27ce65f-684c-49f2-93d0-e446c61f9f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1 : torch.Size([16, 3, 256, 256])\n",
      "step 2 : torch.Size([16, 10, 61, 61])\n",
      "step 3 : torch.Size([16, 10, 30, 30])\n",
      "step 4 : torch.Size([16, 20, 26, 26])\n",
      "step 5 : torch.Size([16, 13520])\n",
      "step 6 : torch.Size([16, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CLOUD_MultiLayerCNN                      [16, 3]                   --\n",
       "├─BatchNorm2d: 1-1                       [16, 3, 256, 256]         6\n",
       "├─Conv2d: 1-2                            [16, 10, 247, 247]        3,010\n",
       "├─MaxPool2d: 1-3                         [16, 10, 61, 61]          --\n",
       "├─Dropout: 1-4                           [16, 10, 61, 61]          --\n",
       "├─AvgPool2d: 1-5                         [16, 10, 30, 30]          --\n",
       "├─Conv2d: 1-6                            [16, 20, 26, 26]          5,020\n",
       "├─Dropout: 1-7                           [16, 20, 26, 26]          --\n",
       "├─Linear: 1-8                            [16, 3]                   40,563\n",
       "==========================================================================================\n",
       "Total params: 48,599\n",
       "Trainable params: 48,599\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.99\n",
       "==========================================================================================\n",
       "Input size (MB): 12.58\n",
       "Forward/backward pass size (MB): 104.99\n",
       "Params size (MB): 0.19\n",
       "Estimated Total Size (MB): 117.77\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = (16, 3, 256, 256)\n",
    "summary(net, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d64fcb-6da2-4352-abf4-25c813e7977e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
